<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Zishun Yu"><title>Self-critical Sequence Training for Image Captioning with SPICE · Zishun's Blog</title><meta name="description" content="This is a project of interset and topic of this project is Self-critical Sequence Training for image captioning with SPICE. In this study, I was inspi"><meta name="keywords" content><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML" async></script><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">Perception</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">認識能力</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">Home</a></li><li></li><li><a href="/404.html"></a></li><li><a href="/index.html"></a></li><li><a href="/Blog/index.html" class="current">Blog</a></li><li><a href="/CV/index.html">CV</a></li><li class="soc"><a href="https://github.com/ZishunYu" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://www.zishun.xyz" rel="noopener noreferrer">Zishun Yu</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a class="a-post">Self-critical Sequence Training for Image Captioning with SPICE</a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2019-05-08</span></p><p class="post-abstract"></p><p><br></p>
<p>This is a project of interset and topic of this project is <strong>Self-critical Sequence Training for image captioning with SPICE</strong>. In this study, I was inspired by the paper <em>self-critical sequence training for image captioning</em> [@DBLP:journals/corr/RennieMMRG16] (SCST) which is using REINFORCE algorithm with baseline to train a sequence generation model to do image captioning task. </p>
<p>I further investigated several evaluation metrics, which is not be used in the SCST, to be directly optimized. The metrics I studied are SPICE, LTEIC (learning to evaluating image captioning) and SPIDEr (linear combination of SPICE and SPIDEr, inspired by [@DBLP:journals/corr/LiuZYG016]). </p>
<p>I found that directly optimizing SPICE will not lead us a better results overall mainly because the testing metrics I report on are mostly syntactic-based but SPICE is semantic-based. Optimizing SPIDEr shows a slightly better performance than optimizing CIDEr, which has a decent improvement on SPICE with relatively small trade-off on BLEU and CIDEr.</p>
<p><br></p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Image caption has been a widely studied NLP task. However, there are still two challenges when using supervised learning. The first challenge is exposure bias, mentioned by [@ranzato2015sequence]. In detail, some text generation models are trained to predict next word given the previous ground truth word, but at test time, the prediction of next word will be made given a generated word instead of the previous ground truth word. As a result, the errors will be accumulated and I refer this as exposure bias since those models are never exposed to its predictions during training. Another is that most generative models are evaluated by non-differentiable NLP metrics such as BLEU [@papineni2002bleu], ROUGE [@lin2004rouge], METEOR [@banerjee2005meteor], CIDEr [@vedantam2015cider] and SPICE [@anderson2016spice], however these models are trained by cross entropy which means the training is not directly optimizing the evaluation metrics.</p>
<p>For addressing these issues, [@ranzato2015sequence] firstly applied policy gradient to do image captioning and [@bahdanau2016actor] employeed actor-critic [@konda2000actor] algorithm. Afterwards, [@DBLP:journals/corr/RennieMMRG16] and [@DBLP:journals/corr/LiuZYG016] both use policy gradient methods to build sequence generation model. </p>
<p>Hence, I developed this project based on the paper <em>self-critical sequence training for image captioning</em>. And for reinforcement learning training, the reward fucntion design is very crusial and in self-critical paper, they used CIDEr as the reward metric. Therefore, our motiviation is to examinate varies of metrics not tested in SCST paper and hopefully I can make some improvement on the results.</p>
<p><br></p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p>I keep kept the same models structure and REINFORCE algorithm which the self-critical sequence training paper used. Therefore, I could better focus on the reward metrics study. Due to the length limitation, some prerequisites knowledge can be found in the report which including following sections in detail:</p>
<ul>
<li>Captioning model</li>
<li>REINFORCE algorithm</li>
<li>REINFORCE algorithm with baseline</li>
</ul>
<p><br></p>
<h4 id="self-critical-sequence-training"><a href="#self-critical-sequence-training" class="headerlink" title="self-critical sequence training"></a>self-critical sequence training</h4><p>Self-critical sequence training (SCST) is the key method of this project, proposed by [@DBLP:journals/corr/RennieMMRG16]. The idea of SCST is using the current model under inference algorithm, i.e. greedy decoding, as a baseline for the REINFORCE algorithm. Therefore, the gradient can be written as following:</p>
<p>\begin{equation}<br>  \frac{\partial L(\theta)}{\partial s_{t}}\approx (r(w^s)-r(\hat{w}))(p_{\theta}(w_{t}|h_t)- 1_{w^s_{t}})<br>  \label{eq:GradientREINFORCE_b}<br>\end{equation}<br>\begin{equation}<br>  \hat{w}<em>t = \arg \max</em>{w_t} p(w_t\,|\,h_t)<br>\end{equation}<br>where $r(\hat{w})$ is the reward obtained by the current model under inference mode, i.e. picking the word with maximum probablity instead of sampling word. Therefore if the sampled senetence obtain a higher reward $r(w^s)$ compared with greddy decoding reward $r(\hat{w})$. The probabily of $w^s$ will be therefore increased. (See Figure 1 for details)</p>
<center><br>    <img src="https://i.postimg.cc/5xZ7Dwhk/SCST.png" width="100%" height="100%"><br>    <br><br>    <font size="3">Figure 1. Self-critical sequence training (SCST). The weight put on words of a sampled sentence from the model is deter- mined by the difference between the reward for the sampled sentence and the reward obtained by the estimated sentence under the test-time inference procedure (greedy inference depicted). This harmonizes learning with the inference procedure, and lowers the variance of the gradients, improving the training procedure.</font><br></center>

<p><br></p>
<h3 id="Reward-Metrics"><a href="#Reward-Metrics" class="headerlink" title="Reward Metrics"></a>Reward Metrics</h3><p><br></p>
<h4 id="Semantic-propositional-image-caption-evaluation"><a href="#Semantic-propositional-image-caption-evaluation" class="headerlink" title="Semantic propositional image caption evaluation"></a>Semantic propositional image caption evaluation</h4><p>SPICE [@anderson2016spice] is a automatic image caption evalution metric which compares the semantic propositional content. Given a image $I$ with some references captions, usually generated by human, and a machine generated caption $c$. The SPICE score, $SPICE(c,S)$, indicate how good the machine-generated caption is. </p>
<p>Besides I encountered some issues with the default package. Details of SPICE package and my solution to its issues can be also found in the <a href="2019/05/07/SPICE/index.html">previous post</a>.</p>
<p><br></p>
<h4 id="Learning-to-evaluate-image-captioning"><a href="#Learning-to-evaluate-image-captioning" class="headerlink" title="Learning to evaluate image captioning"></a>Learning to evaluate image captioning</h4><p>So far, all evaluation mertics mentioned are rule-based automatic metric. Researchers [@cui2018learning], [@sharif-etal-2018-learning] start to get interested in learning-based evaluation metrics because learning-based methods not require expert-level linguistic knowledge but can be very powerful sometimes. Therefore, we choose the <em>Learning to evaluate image captioning</em> (LTEIC) to examinate how learning-based metric would performe as a reward metric.</p>
<p>It turns out the LTEIC model has a large bias, see my <a href="/2019/05/09/Discriminator/index.html">next post</a>, so result of LTEIC will not be reported later (but can be found in the next post also).</p>
<p><br></p>
<h3 id="Experiments-and-Results"><a href="#Experiments-and-Results" class="headerlink" title="Experiments and Results"></a>Experiments and Results</h3><p><br></p>
<h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p>I use the same dataset, MSCOCO dataset [@lin2014microsoft], and keep the same dataset split with the SCST paper. The training set contains 113,287 images and 5 reference captions each image, validation set contains 5k images and results are reported on a testing set contains 5k images. And our results will be reported on 5 widely used image caption evalution mertics, including BLEU4, METEOR, ROUGE-L, CIDEr and SPICE.</p>
<p><br></p>
<h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p>At beginning, I hope directly optimizing SPICE could outperform the baseline, directly optimizing CIDEr, but it turns out directly optimizing SPICE might lead other metircs drop. A quick guess is, most of evaluation metrics I use is syntactic but SPICE is semantic based as figure below shows. Therefore, optimizing SPICE may not improve the syntactic quality, i.e. cause other scores droping.</p>
<center><br>    <img src="https://i.postimg.cc/8zYKpWjc/metrics.png" width="35%" height="35%"><br>    <font size="3">Figure 2. evalution metrics overview</font><br></center>

<p><br></p>
<p>Inspired by [@DBLP:journals/corr/LiuZYG016], a linear combination of both CIDEr and SPICE might cover all aspects, lexical, syntactic and semantic. Hence, we further employeed the linear combination of CIDEr and SPICE (SPIDEr) as a reward metric. Hence, we report 5 sets experiments results, including CIDEr, SPICE, SPIDEr(.5), SPIDEr(.8) and LTEIC (where .5 and .8 is the weight of SPICE score). </p>
<p><br></p>
<h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><p>5 sets experiments are trained with 40 epoches each and evaluate the model on test set every 6000 iterations. The last evaluation results on test set are reported in table below:</p>
<font size="3">Table 1. experiment results, <strong>bold font</strong> indicate the best result in all experiments, <br> <strong>underline</strong> indicate outperforming the baseline</font>

<table>
<thead>
<tr>
<th>Experiments</th>
<th style="text-align:center">BLEU4</th>
<th style="text-align:center">METEOR</th>
<th style="text-align:center">ROUGE-L</th>
<th style="text-align:center">CIDEr</th>
<th style="text-align:center">SPICE</th>
</tr>
</thead>
<tbody>
<tr>
<td>CIDEr(baseline)</td>
<td style="text-align:center"><strong>0.323</strong></td>
<td style="text-align:center">0.256</td>
<td style="text-align:center">0.544</td>
<td style="text-align:center"><strong>1.063</strong></td>
<td style="text-align:center">0.188</td>
</tr>
<tr>
<td>SPICE</td>
<td style="text-align:center">0.186</td>
<td style="text-align:center">0.250</td>
<td style="text-align:center">0.471</td>
<td style="text-align:center">0.602</td>
<td style="text-align:center"><strong>0.241</strong></td>
</tr>
<tr>
<td>SPIDEr(.5)</td>
<td style="text-align:center">0.321</td>
<td style="text-align:center"><strong>0.258</strong></td>
<td style="text-align:center"><strong><strong>0.545</strong></strong></td>
<td style="text-align:center">1.058</td>
<td style="text-align:center"><strong>0.196</strong></td>
</tr>
<tr>
<td>SPIDEr(.8)</td>
<td style="text-align:center">0.312</td>
<td style="text-align:center"><strong><strong>0.261</strong></strong></td>
<td style="text-align:center">0.541</td>
<td style="text-align:center">1.040</td>
<td style="text-align:center"><strong>0.207</strong></td>
</tr>
</tbody>
</table>
<p><br><br>In general, directly optimzing SPICE might cause a worse results overall as we previously discussed but end with a very high SPICE score. Optimzing LTEIC does not work at all as we expected. Optimzing CIDEr, SPIDEr(.5) and SPIDEr(.8) seems have very close results, no one is dominating others. Therefore we compared these 3 experiments, taking optimizing CIDEr as baseline, in figure below. It shows optimizing SPIDEr has a little sacrifices on BLEU4 and CIDEr but will lead a decent improvement on SPICE (and small improvement on METEOR).</p>
<p><center><br>    <img src="https://i.postimg.cc/xTtpZBQK/comparison.png" width="70%" height="70%"><br>    <font size="3">Figure 3. improvement\% compared with baseline (optmizing CIDEr)</font><br></center><br><br><br>Besides, example captions from different models on 10 randomly selected COCO images can be found in table below.</p>
<font size="3">Table 2. ungrammatically captions when directly optimizing SPICE</font>

<table>
<thead>
<tr>
<th>Image</th>
<th style="text-align:center">Ground Truth Captions</th>
<th style="text-align:center">Generated Captions</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://i.postimg.cc/G3P5FHSg/COCO-val2014-000000057363.jpg" width="80%" height="80%"></td>
<td style="text-align:center">a red and yellow fire truck and some buildings<br>An overhead view shows a fire engine in the street.<br>A red and yellow fire truck with ladders on top<br>A firetruck is parked in the street in between stop lights.<br>A fire truck (ladder truck) drives down a street in the city.</td>
<td style="text-align:center">CIDEr: a red fire truck parked on the side of a street<br>SPICE: a red fire truck parked on a city street together a building together a man<br>SPIDEr(.5): a red fire truck parked on the side of a street<br>SPIDEr(.8): a red fire truck parked in front of a street</td>
</tr>
<tr>
<td><img src="https://i.postimg.cc/028HcPTk/COCO-val2014-000000541924.jpg" width="80%" height="80%"></td>
<td style="text-align:center">A woman walking on a city street in a red coat.<br>A group of people that are standing on the side of a street.<br>A woman in a red jacket crossing the street<br>a street light some people and a woman wearing a red jacket<br>A blonde woman in a red coat crosses the street with her friend.</td>
<td style="text-align:center">CIDEr: a woman walking down a street with a traffic light<br>SPICE: a group of people and a woman walking down a city street with a traffic light<br>SPIDEr(.5): a group of people walking down a street<br>SPIDEr(.8): a group of people walking down a city street</td>
</tr>
</tbody>
</table>
<p><br></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Directly optimizing SPICE will not lead us a better results overall mainly because the testing metrics we report on are mostly syntactic-based but SPICE is semantic-based. And LTEIC itself has a very strong bias (see <a href="/2019/05/09/Discriminator/index.html">next post</a> for details), therefore it doesn’t work and indeed we didn’t expect it to work. </p>
<p>Optimizing SPIDEr shows a slightly better performance than optimizing CIDEr, which has a decent improvement on SPICE with relatively small trade-off on BLEU and CIDEr.</p>
<p><br></p>
<h3 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h3><p>I acknowledgment Dr. Natalie Parde for advices on this project.<br>Thanks Ruotian Luo for high-quality implementation of <a href="https://github.com/ruotianluo/self-critical.pytorch" target="_blank" rel="noopener"><em>self-critical sequence training</em></a>.<br>Thanks Yin Cui for releasing their code for <a href="https://github.com/richardaecn/cvpr18-caption-eval" target="_blank" rel="noopener"><em>learning to evaluate image captioning</em></a><br>And I would like to thank Dr. Natalie Parde, Dr. Siqi Liu for advices on improving SPICE time efficiency.</p>
<p><br></p>
<h3 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h3><p></p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a href="http://twitter.com/home?status=http://www.zishun.xyz/Blog/2019/05/08/Self-critical/%20Zishun's Blog%20Self-critical Sequence Training for Image Captioning with SPICE" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/Blog/2019/05/09/Discriminator/" title="Optimizing Learning-Based Metric for Image Captioning"><i class="fa fa-angle-double-left"></i>&nbsp;Previous post: Optimizing Learning-Based Metric for Image Captioning</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/Blog/2019/05/07/SPICE/" title="Issues with SPICE Package and Solution">Next post: Issues with SPICE Package and Solution&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://www.zishun.xyz" rel="noopener noreferrer">Zishun Yu</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>